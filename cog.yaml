# Configuration for Cog ⚙️
# Reference: https://github.com/replicate/cog/blob/main/docs/yaml.md

build:
  cuda: "12.1"
  cudnn: "8"
  gpu: true
  python_packages:
  - jinja2
  python_version: 3.11.9
  run:
  - command: --mount=type=cache,target=/root/.cache/pip TORCH_CUDA_ARCH_LIST="9.0"
      CUDA_HOME=/usr/local/cuda pip install --ignore-installed \ git+https://github.com/neuralmagic/nm-vllm@fbgemm-checkpoints
      \ git+https://github.com/huggingface/transformers.git@new-quant-method \ accelerate
  - command: --mount=type=cache,target=/root/.cache/pip pip install cog==0.10.0a16
  - command: curl -o /usr/local/bin/pget -L "https://github.com/replicate/pget/releases/download/v0.8.1/pget_linux_x86_64"
      && chmod +x /usr/local/bin/pget
  - command: sed -i "s/from vllm.model_executor.layers.quantization.schema import
      QuantParamSchema/# from vllm.model_executor.layers.quantization.schema import
      QuantParamSchema/" /root/.pyenv/versions/3.11.9/lib/python3.11/site-packages/vllm/model_executor/model_loader/weight_utils.py
concurrency:
  max: 16
predict: predict.py:Predictor
train: train.py:train
